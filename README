This is test code to get AWS ElasticCache cleint code to correctly access a scaled Memcached cluster.
Our aim was to write lambda functions in response to an event monitoring one of the memcached metrics, to do the
auto scaling. As we describe below it is impossible to do the autoscaling from the lambda.
It needs to be done via the client application as we describe below.

First some facts:
1. It takes between 3 to 4 minutes to add or remove a memcached node.
2. According to this doc https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/BestPractices.LoadBalancing.html,
   we need to use consistent hashing. This is supplied by pymemcache HashClient
3. AutoDiscovery should be used to check the addition or removal of a node,
   https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/AutoDiscovery.html
4. When Removing Nodes from a Cluster the doc https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Clusters.DeleteNode.html says,
   "Each time you change the number of nodes in a Memcached cluster, you must re-map at least some of your keyspace so it maps to the correct node."
   The doc on adding nodes, https://docs.aws.amazon.com/AmazonElastiCache/latest/mem-ug/Clusters.AddNode.html
   says the same thing, so in this case we would need to remap all the keys.
   Algorithm for adding & deleting node with key remapping is described below.


A node is removed in 2 ways:
1.  Physically dies
2.  Removed by auto scaling

In the case of a node physically dying there is obviously no way to remap any keys and subsequent gets could cause an exception.
Also pymemcache itself could remove a dead node almost simultaneously with the AutoDiscovery kicking in
So one must be careful that this does not cause an exception also.
AutoDiscovery should remove this node from the client within at most one minute.

If the auto scaling is done by the lambda including key remapping, as described in 4 above, the client will continue
to assume the key is mapped to the specific node which may have been deleted in the case of removibg a node.
Even when a new node is added the mapping changes so the key wont be found.
So adding and deleting must be an integral part of the AutoDiscovery class.

For removing a node algorithm will work as follows with pymemcache:
1.  Decide which node is to be removed
2.  Make a HashClient with just that node
3.  Use the HashClient to get all the keys on that node.
4.  Remove the node from the AutoDiscovery class
5.  For each key found get its value from the to be deleted HashClient and add it to the AutoDiscovery class
6.  Delete the node from ElasticCache

For adding a node this is the algorithm:
1.  Add node
2.  Wait till it comes alive
3.  Add the IP of the new node to AutoDiscovery class
4.  For each node IP, excluding the new one that was added create a HashClient
    For each key from the HashClient that does not exist in the AutoDiscovery class, get its value from the HashClient and remap it


AutoClient.py tests an auto discovery client based on pymemcache HashClient which apparently uses consistent hashing.
To add a node touch a file called add.node in the same folder as the running client.
To remove a node touch del.node
Of course a real app will have a lambda that fires on a metric or 2 and calls a REST API that will do the add/delete node
in the AutoDiscovery client
You need to have memcached tools installed as memdump is used to list the keys.


None of the other files in this project have any relevance.
They were all for test purposes.
